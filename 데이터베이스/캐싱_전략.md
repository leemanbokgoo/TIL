# 캐싱 전략
- 캐싱은 자주 사용되는 데이터를 임시 저장소에 저장하여, 필요할 때 빠르게 접근할 수 있도록 하는 기술이다. 캐시는 메모리, 디스크, 또는 네트워크 상의 다른 위치에 저장될 수 있다.
- 캐싱의 주요 목적은 데이터 접근 속도를 높이고 시스템의 성능을 최적화하는 것이다. 이를 통해 데이터베이스나 원격 서버에 대한 불필요한 요청을 줄일 수 있다.
- 왜냐하면 캐싱은 자주 사용되는 데이터를 미리 저장하여, 필요할 때 빠르게 접근할 수 있도록 하기 때문이다. 이를 통해 시스템의 응답 시간을 단축하고, 서버 부하를 줄일 수 있다.

## LRU (Least Recently Used)
- LRU 캐싱은 최근에 접근한 데이터를 유지하고, 오랫동안 사용되지 않은 데이터를 제거하는 방식이다. 이는 최근에 접근한 데이터가 곧 다시 사용될 가능성이 높고 가장 오랫동안 사용하지 않았던 데이터라면 앞으로도 사용할 확률이 적다고 판단하기 때문이다. 따라서 최근 접근 패턴이 중요한 시나리오에 적합하다.

![Image](https://github.com/user-attachments/assets/251f1369-47a2-43e1-a102-a704f75a5cb2)

- Input : 123145 인 상황에서 4초를 보면 원래 있었던 1이 한번 더 입력되므로 1을 참조한다. 참조 후 오랫동안 참조하지 않은 순으로 바꾸면 2->3->1이 된다. 6초에는 cache size가 가득차 5가 들어갈 수 없으므로, 가장 오랫동안 참조되지 않은 2를 제거한 후 저장한다.
    - Output : 5413
- 캐시의 크기가 3인데 이미 3개의 페이지가 캐시에 들어가 더이상 빈 공간이 없다면 맨 뒤에 페이지번호 node를 지우고 새로운 페이지번호 node를 앞에 연결해주는 방식이다. 여기서 알 수 있는 건 LRU를 구현할 때는 더블 링크드 리스트를 사용하고 head에 가까울 수록 최근에 참조한, tail에 가까울수록 오랫동안 참조되지 않은 노드라는 것을 알 수 있다.
- 시간 순서를 기록하는 LinkedHashMap, Doubly Linked List + HashMap 등으로 구현된다.
- LRU는 최근 사용 여부를 기준으로 데이터를 교체하기 때문에 적중률이 높고 현실적인 접근 방식으로 널리 사용된다. 성능과 효율의 균형이 좋아 실제 시스템에서 가장 널리 사용되는 알고리즘 중 하나이다.

### 장점
- 빠른 액세스 : 가장 최근에 사용한 아이템부터 가장 오래전에 사용한 아이템까지 정렬된다.
따라서 두 아이템에 접근할 경우, O(n)의 시간 복잡도를 가진다.
- 빠른 update : 하나의 아이템에 액세스 할때마다 업데이트 되며, O(n)의 시간 복잡도를 가진다.
- 시간 기반 접근으로 직관적이며 메모리 히트율이 높음

### 단점
- 많은 공간 차지한다. n개의 아이템을 저장하는 LRU는 N의 크기를 가지는 1개의 Linked-list(queue)와 이를 추적하기 위한 n의 크기를 가지는 1개의 hash-map이 필요하다. 이는 O(n)의 복잡도를 가지지만, 2개의 데이터 구조를 사용해야 한다는 단점이 있다.
- 자주 접근되지만 일시적으로 사용되지 않은 데이터도 제거될 수 있다.
- 시간 갱신 처리를 위한 데이터 이동 비용이 존재한다. (O(1) 유지 위해 자료구조 설계 필요)
- 최근 사용 내역을 추적하기 위한 추가 자료구조와 연산이 필요하여 FIFO나 LFU보다 구현이 더 복잡하고 메모리 오버헤드가 존재할 수 있다.

### LRU 사용사례 
- 소셜 미디어 피드
    - 소셜 미디어 사용자는 새로운 콘텐츠로 계속 업데이트되는 피드를 스크롤한다.
    - LRU를 사용하여 최근에 본 게시물과 이미지를 캐시에 저장하고, 오래된 게시물을 제거한다. 이를 통해 최신 콘텐츠를 빠르게 불러올 수 있다.
- 웹 브라우저의 방문 기록, 이미지 캐시
    - 웹 브라우저는 최근에 방문한 웹 페이지를 캐시에 저장하여 탐색 속도를 향상시킨다.
    - LRU를 사용하여 최근에 방문한 웹 페이지를 캐시에 저장하고, 오래된 페이지를 제거한다. 이를 통해 사용자는 최근 방문한 페이지를 빠르게 다시 접근할 수 있다.

## LFU (Least Frequently Used)
- LFU 캐싱은 가장 자주 접근된 데이터를 유지하고, 덜 자주 접근된 데이터를 제거하는 방식이다. 이는 데이터의 중요도가 얼마나 자주 접근되었는지에 따라 결정되는 시나리오에 유용하다.
- 사용 빈도 수를 기반으로 가장 적게 사용된 데이터를 제거하고 접근 시마다 카운터를 증가시킨다. 카운터 빈도 수가 낮은 데이터를 제거하여 ‘덜 인기 있는 데이터’를 비우는 방식으로 동작한다.

### 장점
- 단순히 시간 순서가 아니라, 실제 활용도를 기준으로 캐시 유지
- 데이터가 자주 참조되면 오래 유지됨 (인기 데이터 보호)

### 단점
- 빈도 카운팅을 위한 추가 메모리 및 연산 비용
- 최근 트렌드를 반영하지 못할 수 있음 한 번 많이 사용된 후 사용 안 되더라도 유지될 수 있기때문에 최근에는 사용하지않는 데이터라도 사용횟수가 많다면 계속 유지될 수 있음.
- 동일 빈도 시 우선순위 판단 어렵다 (LRU와 혼합하여 LFU-LRU 전략을 쓰기도 한다)

### LFU 사용사례 
- 음악 스트리밍 앱
    - 사용자는 자주 듣는 노래나 플레이리스트를 반복해서 재생한다.
    - LFU를 사용하여 가장 자주 재생되는 노래를 캐시에 저장하고, 덜 재생되는 노래를 제거한다. 이를 통해 자주 듣는 노래를 빠르게 재생할 수 있다.
- 전자책 리더
    - 사용자는 특정 책이나 챕터를 반복해서 읽을 수 있다.
    - LFU를 사용하여 가장 자주 읽는 책이나 챕터를 캐시에 저장하고, 덜 읽는 항목을 제거한다. 이를 통해 즐겨 읽는 책을 빠르게 접근할 수 있다.
- 쇼핑 앱
    - 특정 상품은 사용자가 자주 검색하고 조회할 수 있다.
    - LFU를 사용하여 자주 조회되는 상품 페이지를 캐시에 저장하고, 덜 조회되는 페이지를 제거한다. 이를 통해 인기 있는 상품을 빠르게 접근할 수 있다.


## FIFO(First In First Out)
- 가장 먼저 저장된 데이터를 제거하고, 새로운 데이터를 저장하는 방식이다. 왜냐하면 오래된 데이터를 제거하여, 캐시의 효율성을 높일 수 있기 때문이다. 들어온 순서만 고려하여 가장 오래된 데이터를 제거 한다. 큐(Queue) 기반으로 간단하게 구현 가능하다.
- FIFO는 큐라는 자료구조를 참고하면 이해하기가 쉬운데, 가로로 긴 파이프 모형을 상상하고 한쪽에 구슬을 넣으면 자연스럽게 다른 한쪽은 그 구슬이 나오게 되는 형태를 상상하면 된다. 한쪽은 입력만 한쪽은 출력만 실행한다.

### 장점
- 구현이 매우 단순하고 직관적
- 빈도, 시간 추적 필요 없음 → 오버헤드 적음

### 단점
- 데이터 재사용 가능성과 무관하게 제거 → 히트율 낮을 수 있다
- 자주 사용하는 데이터라도 먼저 들어왔으면 삭제될 수 있다. 
- 데이터의 실제 사용 여부를 고려하지 않고 먼저 들어온 항목을 제거하기 때문에, 캐시 미스율이 비정상적으로 증가할 수 있으며, Belady’s anomaly와 같은 현상을 유발할 수 있다.
    - 캐스 미스율 : 전체 요청 중에서 캐시에 데이터가 없어서 새로 가져와야 하는 비율
        - 캐시 미스율 = (캐시 미스 횟수) / (전체 요청 횟수)
        - 총 100번의 요청 중 30번이 캐시에 없었다면 → 캐시 미스율 = 30%
    -  벨라디의 모순 (Belady’s anomaly) : 캐시(또는 페이지 프레임)의 크기를 늘렸는데도 캐시 미스율이 오히려 증가하는 비정상적인 현상으로 FIFO처럼 단순한 캐시 전략에서 발생할 수 있다. 캐시 크기를 늘려도 오히려 캐시 미스율이 높아지는 비정상적인 현상으로 캐시 교체 정책이 데이터의 중요성을 고려하지 않기 때문에 발생한다.

### 사용 사례
- 스트리밍 서비스에서 버퍼 관리
- 단순한 임베디드 시스템, 메모리 제약이 큰 환경
- Queue를 기반으로 한 기본적인 캐시 시스템

----

창고링크 

https://medium.com/@insub4067/%EB%AA%A8%EB%B0%94%EC%9D%BC-%EC%95%B1-%EC%84%9C%EB%B9%84%EC%8A%A4%EC%97%90%EC%84%9C-lru%EC%99%80-lfu%EB%A5%BC-%EC%96%B8%EC%A0%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%A9%B4-%EC%A2%8B%EC%9D%84%EA%B9%8C-4c4925e2f3f8

https://velog.io/@ddyy094/LRULeast-Recently-Used-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%9D%B4%EB%9E%80
