# Rate Limiting
- API Rate Limiting은 API에 대한 요청 수를 일정 시간 동안 제한하는 메커니즘이다. 주로 서비스의 안정성을 유지하고, 특정 API에 대한 과도한 요청으로 인해 발생할 수 있는 문제를 방지하기 위해 사용된다. 예를 들어, 특정 API가 초당 100개의 요청만 허용한다고 설정하면 그 한도를 초과하는 요청은 차단되거나 지연 처리된다.
- Rate Limiter는 처리율 제한 장치라는 의미로써, 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 컨트롤 하기 위한 장치를 의미한다.
Rate Limiter를 적용하면 서비스에 너무 많은 요청이 몰리는 것을 방지할 수 있고 그로 인해 서비스를 안정적으로 운영할 수 있도록 할 수 있다.
- 예를 들어 서버세 호출 할 수 있는 횟수를 1분당 60회(60회가 임계치)로 임계치를 정해둔다면 60회를 넘어선 순간부터는 요청을 처리해주지 않고 에러를 리턴하는 정책을 세울 수 있다. 이를 Throttling이라고도 표현하는데 쉽게 말하면 정해진 시간동안 처리 할 수 있는 operation의 수를 정하는 것이다.

## Rate Limiter의 장점
- 서비스 안정성 유지할 수 있다. 과도한 요청이 몰릴 경우 시스템 과부하를 방지해 서비스 다운이나 성능 저하를 예방한다.
- 최적화 시스템 자원을 특정 사용자나 클라이언트가 독점하지 못하게 하여 공평하게 리소스 분배할 수 있다.
- DDoS 및 비정상적인 트래픽 방어,악의적인 대량 요청이나 비정상적인 트래픽을 제한해 보안성 강화할 수 있다.
- 비용 절감과도한 요청으로 인한 서버 확장 및 리소스 사용 비용 절감한다.
- 서비스 품질 보장처리량을 제어함으로써 모든 사용자에게 일관된 성능과 안정적인 서비스 제공한다.
- API 남용 방지특정 클라이언트의 과도한 요청을 방지해 시스템을 악용하거나 오용 방지한다.

## Throttling 구현방식
- 유저의 요청 수가 임계치를 넘었을때 이를 제한하는 방식은 크게 3가지로 나눠볼 수 있다. 공통적으로는 유저의 요청수가 초괴하면 HTTP status "429 - Too many reqeusts"를 리턴하게 된다.
- Hard Throttling : throttling limit을 엄격하게 관리(1개라도 넘으면 안됨)
- Soft Throttling : 특정 percentage까지는 throttle limit을 넘기는 것을 허용한다. 예를 들어 rate limit이 분명 100회인데 10%로 잡으면 110회까지는 허용한다.
- Elastic or Dynamic Thorttling : 서버 자원에 여유가 있을때는 Throttling limit을 넘기더라도 요청을 허용한다.

## Rate Limit을 구현시 요구조건
### 기능 측면
- 클라이언트가 서버에 요청할 수 있는 횟수를 특정 임계치까지만 허용한다.(예: 1분당 30회)
- 클라이언트의 요청 횟수가 정책적으로 정해둔 임계치를 넘어설 경우에는 에러를 리턴해야한다.
### 운영 측면
- 안정성 및 가용성 : Rate Limit이 동작하는 서버는 안정적으로 동작해야한다. 수강신청이나 Ddos 공격과 같이 특정 시간에 요청이 급증하는 경우에도 동작해야 한다. 또한 유저수가 많아진다해도 OOM과 같은 이슈가 발생하지 않아야한다.
- 성능 : Rate Limit 서버로 인해 서버의 처리량이 과도하게 늘어나거나 응답시간이 지연되지 않고 빠르게 Rate Limit을 처리할 수 있어야 한다.

## Rate Limit 사용처
- RateLimit은 주로 유저별로 rate limit을 걸긴 하지만 아래와 같은 상황도 고려해볼 수 있다.
    - 유저별 rate limit : userId, API key, IP address 등을 기준으로 특정 유저가 API에 요청할 수 있는 수를 제한
    - Concurrent 서버 rate limit: 특정 유저에 의해 맺을 수 있는 parallel session의 수, Ddos공격 등을 막기 위해 사용

## Rate limit 구현시 주의사항
### 리턴 메세지
- rate limit을 적용하려면 RFC6585에 429 Too Many Request HTTP 상태코드를 사용하려고 제안한다. 또한 rate limit-limit(허용되는 요청의 최대수), RateLimit-Remaining(남은 요청 수), RateLimit-Reset(요청 최대값이 재설정될때까지의 시간)정보를 Header에 같이 보내주면 좋다. 

### 적절한 알고리즘 선택
- Rate Limit 알고리즘은 트래픽 패턴을 잘 분석하고 적절한 알고리즘을 선택하는 것이 매우 중요하다. 예를 들어 분산시스템에서의 활용, 트래픽 체증에 민감하지 않는 경우 등에 따라 다른 알고리즘의 선택이 필요하다. 트래픽이 민감하지않은 경우에는 Token Bucket, 그외에는 Fixed Window나 Sliding Window알고리즘을 선택한다고 한다.

## Rate Limit 아키텍처 설계
- Application Server앞 단에서 웹서버가 Rate Limiter와 통신.
![Image](https://github.com/user-attachments/assets/5f30f410-fe59-410b-8029-29f45445752e)
- 1. Load Balancer는 Rate Limiter에게 Client의 rate limit을 조회한다.
- 2. Rate Limiter는 Rate limiting data를 cached storage의 backend storage에서 관리하며 Load Balancer의 요청에 따라 클라이언트의 요청이 rate를 초과했는 지 여부를 리턴한다.
- 3. 만약 초과했으면 LB는 Application Server에 요청을 전달하지 않고 Clinet의 요청을 거절한다.

## Rate Limit을 분산환경에서 구현 시 주의점
### Inconsistency
- 여러개의 앱서버들이 분산되어 다른 region에서 동작하고 있는 경우, global rate limiter가 필요하다.
    - Sticy Session
        - 로드밸런서에 sticky session을 두고, 특정 유저는 특정 node로만 request를 가도록 해서, local rate limiter를 활용하도록 한다. 이 방법은 scaling할 수 없고, 해당 node가 다운되었을 때 대응을 할 수 없다.
    - Centralized Data store
        - Redis나 Cassancra와 같은 중앙화된 data store를 사용해서 rate limit 정보를 저장한다. 지연 시간이 문제가 될 수 있지만, 조금 더 나은 해결책이다.

### Race Condition
- concurrency가 높아지는 경우, race condition이 발생할 수 있다. 각 node에서 동시에 같은 counter를 저장하려고 하는 경우, counter가 증가하지 못하는 문제가 발생할 수 있기 때문이다. read-write operation에 lock을 활용할 수 있지만, 지연 시간 문제가 발생할 수 있다.

### 분산환경에서 Centralized DB를 활용한 rate synchronization
- 실제로 race condition을 고려한 상세한 아키텍처는 아래와 같다.
![Image](https://github.com/user-attachments/assets/506f52e6-bd56-4771-bec5-0406629ed2d6)
- 많은 global lock으로 인한 레이턴시를 줄이기위해 로컬 메모리에 rate를 업데이트하고 주기적으로 centralized storage와 동기화하는 방식이다. 이 아키텍처의 포인트는 로컬 메모리와 centralized inconsistency를 해결해주는 syschronization service가 별도로 있어야한다는 점이다.



## 구현 알고리즘 방식
### 토큰방식(Toeken Bucket) 알고리즘 

![Image](https://github.com/user-attachments/assets/a3bd9756-3c91-4761-9721-84a4d327a357)

- 토큰 버킷 방식을 간단하게 설명하면 큰 물통에 물이 계속 채워지는 방식이다. 물통에 물이 가득 차게 되고 요청이 올때 마다 물통에 물이 하나씩 빠지게 된다. 시간이 지남에 따라 주기적으로 물이 채워지게 되고 만약 물통에 물이 가득찬 상태라면 더 이상 물을 채워지지 않게 된다. 만약, 토큰이 충분하지 않은 경우(즉, 물통에 물이 없는 경우)에는 해당 요청은 버려지게 된다.
- Token Bucket은 가장 널리 사용되는 Rate Limiting 알고리즘 중 하나다. 이 알고리즘은 다음과 같은 방식으로 작동한다
    - 일정한 속도로 토큰을 버킷에 추가한다. 버킷은 정해진 크기를 가지고 있으며, 최대 크기를 초과할 수 없다.
    - 클라이언트가 요청을 보낼 때마다 버킷에서 토큰 하나를 소모한다. 만약 버킷에 토큰이 남아있지 않다면 요청이 거부되거나 지연된다.
        - 충분한 토큰이 있는 경우: 버킷에서 토큰 하나를 꺼낸 후, 요청을 시스템에 전달한다.
        - 충분한 토큰이 없는 경우: 해당 요청은 버려진다 (dropped)
- 토큰이 버킷에 충분히 있다면 요청이 즉시 처리된다.
### 유의할 점
- 분산시스템에서, 만약 하나의 토큰만 남아있는 상황에서 두 서버의 Redis 작업이 서로 겹치면 두 요청 모두 허용될 것이다.
- Redis lock을 획득한다면 원자성을 지킬 수 있겠지만, 동시 요청 처리 속도를 늦추는 대가를 치르게 된다.
- 이를 방지하려면, Lua scripting을 이용해 Redis의 작업을 원자적으로 만들 수 있다.

### 장점
- 구현이 쉽다.
- 메모리 사용 측면에서 효율적이다.
- 짧은 시간 burst 트래픽(짧은 시간 내에 집중된 트래픽)을 허용하면서도 전체적인 요청 속도를 제한하는 데 유용하다. 버킷에 남은 토큰이 있기만 하면 요청은 시스템에 전달될 것이다.

### 단점
- 버킷 크기와 토큰 공급률이라는 두 개의 인자를 가지고 있는데, 이 값을 튜닝하는 것이 까다로운 일이다.

### 누출 버킷(Leaky Bucket) 알고리즘
- 누출 버킷 알고리즘은 버킷 알고리즘과 거의 유사하다. 물통에 물이 채워지고 사용하는 방식은 동일하나 요청 처리율이 고정으로 되어 있다는 점이 다르다. 누출 버킷 알고리즘의 동작 원리는 다음과 같다.
    - 요청이 도착하면 큐가 가득 차 있는지 체크한다. 빈자리가 있는 경우에는 큐에 요청을 추가한다.
    - 큐가 가득 차 있는 경우에는 새 요청은 버리게 된다.
    - 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.
![Image](https://github.com/user-attachments/assets/932487b0-832a-4ff9-9d5a-41e9d2c3fefb)
- 이 알고리즘은 트래픽이 갑자기 증가하는 것을 방지하고, 일정한 속도로 트래픽을 처리하는 데 효과적이다.

### 고정 윈도우 카운터(Fixed Window Counter) 알고리즘
- 시간 단위를 "고정된 윈도우(시간 창)"로 나누어 요청 수를 제한하는 방식이다. 동작 원리는 다음과 같다.
- 고정된 시간 단위(예: 1초, 1분, 1시간)를 기준으로 윈도우를 나눕니다.
- 각 윈도우에서 발생하는 요청 수를 카운터로 기록합니다.
- 요청이 발생할 때마다 카운터를 증가시키고, 설정된 최대 요청 수(Threshold)를 초과하면 새로운 요청은 새 윈도우가 열릴 때까지 버려진다.
- 시간이 지나 새로운 윈도우가 시작되면 카운터는 초기화됩니다.
- 아래 타임라인을 살펴보면 시스템은 초당 3개의 요청만을 허용할 수 있다. 매초마다 열리는 윈도우의 개수는 3개이며 3개 이상 요청하게 되면 그 초과분은 버려지게 된다.

![Image](https://github.com/user-attachments/assets/41194c9c-fc05-4613-a3bc-c5f178488f19)

- 이 알고리즘의 가장 큰 문제는 윈도우의 경계부근에서 순간적으로 많은 트래픽이 집중될 경우 윈도우에 할당된 양보다 더 많은 요청이 처리될 수 있다.
- 예를 들어 분당 최대 5개를 처리한다고 가정한다. 분당 처리이기에 10:00~10:01에 5건이 요청되고 10:01~10:02 사이에 또 다시 5건이 요청 되었다. 이렇게 보면 1분당 5건을 처리한게 맞다.

![Image](https://github.com/user-attachments/assets/44b4b74f-b03e-4a0d-bb7a-c62968782548)

- 그러나 위의 그림에서와 같이 각각의 10:00:30에 5건이 순차 인입되고 10:01:30 전까지 5건이 인입되었다고 가정하면 10:00:30~10:01:30는 1분이지만 실제로는 10건이 처리되어 허용 한도를 2배까지 들어오게 되는 문제가 있다.
- 이 방법은 구현이 간단하지만, 시간 창 경계에서 트래픽이 집중될 때 “thundering herd” 문제(한 시간 창의 끝에서 시작으로 넘어가는 시점에 많은 요청이 몰리는 현상)가 발생할 수 있다.

### 이동 윈도우(Sliding Window) 알고리즘
- 시간 창(Window)이 고정된 구간으로 나뉘지 않고, 요청이 발생하는 순간을 기준으로 연속적으로 이동하면서 요청을 제한하는 방식이다.
동작 원리는 다음과 같다.
- 요청이 들어올 때마다 해당 요청의 타임스탬프를 기록한다.(이 때 타임스태프 데이터는 보통 레디스의  정렬 집합 같은 캐시에 보관)
현재 시간을 기준으로, 설정된 윈도우 크기(예: 1분, 10초) 안에 있는 요청의 수를 계산한다.
요청 수가 설정된 최대 허용 값(Threshold)을 초과하면 추가 요청은 버려지게 된다.
윈도우는 요청이 들어올 때마다 갱신되며, 과거 윈도우는 자연스럽게 슬라이딩(이동) 된다
- 예시를 통해 살펴보자. 분당 2개의 처리를 하는 시스템이 있다고 가정하자.

![Image](https://github.com/user-attachments/assets/db136a60-7584-49cf-9c1a-0a0092bc7eb2)

- 요청이 10:00:01에 도착하였을 때는, 로그는 빈 상태이므로 이 요청은 허용된다.
- 새로운 요청이  10:00:30에 도착하였다. 타임스탬프가 로그에 추가되었고 로그의 크기는 2가 되며 허용범위이므로 이 요청 또한 허용된다.
- 새로운 요청이 다시 10:00:40초에 도착하였고 이 타임스탬프 역시 로그에 추가되었다. 추가된 이후 로그의 크기는 3이 되었기 때문에 타임스탬프에 대한 로그는 남아있는 상태로 유지하지만 요청은 거부, 즉 버려지게된다.
- 새로운 요청이 10:01:30초에 도착하였다. 이 타임스탬프 역시 로그에 추가된다. 10:00:30~10:01:30 범위 안에 있는 요청이 아닌 이전에 요청된 10:00:01, 10:00:30는 전부 만료된 값이므로 로그에서 삭제한다. 삭제 이후에 로그의 크기는 2이브로 10:01:30 신규 요청은 허용된다.
- 이 알고리즘은 시간 창 경계에서 발생하는 트래픽 집중 문제를 줄여준다. 하지만 타임스탬프를 저장해야 하므로 메모리 사용량이 증가할 수 있다.

###  이동 윈도우 카운터(Sliding Window Counter) 알고리즘
- 이 방식은 고정 윈도우 카운터 알고리즘과 이동 윈도우 로깅 아록리즘을 결합한 알고리즘이다. 요청 제한(Throttle)을 위해 시간 창(Window)을 연속적으로 슬라이딩(이동)하면서 계산하는 방식이다. 고정된 윈도우와 이벤트가 시간적으로 겹치는 비율을 고려하여 요청 수를 계산하게 된다.
- 동작 원리는 다음과 같다.
    - 두 개의 윈도우 계산
        - 현재 요청이 속한 윈도우(즉, 현재 1분간)의  요청 수
        - 직전 윈도우(직전 1분간)  요청 수
    - 겹치는 비율 계산:
        - 현재 요청이 속한 슬라이딩 구간과 직전 윈도우가 겹치는 비율을 계산한다.(예를 들어, 현재 시점이 1분 윈도우 기준으로 마지막 10초에 해당하면 겹치는 비율은 10/60 = 0.1667이다)
    - 가중치 기반의 최종 요청 수 계산:
        - 최종 요청 수 = (현재 윈도우의 요청 수)+(직전 윈도우의 요청 수×겹치는 비율)
- 예를 들어, 1분에 5개의 요청을 처리하는 시스템이 있다. 
아래 그림과 같이 현재 시간은 12:01:30이고 아래와 같이 현재 1분간 요청된 건은 3건, 직전 1분간 요청건은 4건이다. 
- 이 예제를 통해 현재 요청 수를 계산해보자.
![Image](https://github.com/user-attachments/assets/616522ec-cb00-4eef-9c3d-b92ae975c1c0)
- 1. 윈도우 정의:
    - 현재 윈도우: 12:01:00 ~ 12:02:00
    - 직전 윈도우: 12:00:00 ~ 12:01:00
    - 현재 시각: 12:01:30
- 2. 겹치는 시간 계산:
    - 현재 시각(12:01:30) 기준으로 직전 윈도우와 현재 윈도우가 겹치는 시간:
        - 겹치는 구간은 12:01:00 ~ 12:01:30.
        - 총 겹치는 시간: 30초.
- 3. 겹치는 비율 계산:
    - 겹치는 비율 = 3060=0.5\frac{30}{60} = 0.56030​=0.5 (60초 기준 30초가 겹침).
- 4. 요청 수 데이터:
    - 현재 윈도우의 요청 수: 3건.
    - 직전 윈도우의 요청 수: 4건.
- 5. 최종 요청 수 계산:
    - 계산식: (현재 윈도우 요청 수)+(직전 윈도우 요청 수×겹치는 비율)
    - 대입: 3+(4×0.5)=3+2=5
- 6. 결론:
    - 최종 요청 수 = 5.
    - 허용 한도(5건)에 도달했으므로, 추가 요청은 제한됩니다.

### 질문
### Rate Limiting을 분산 환경에서 구현할 때 주의할 점은 무엇이고, 이를 해결하기 위한 방법은 어떤 것이 있나요?
- 분산 환경에서는 여러 인스턴스나 노드에서 동일한 사용자의 요청이 처리되기 때문에, 개별 인스턴스에 로컬로 Rate Limiting을 적용하면 전체 시스템 차원의 요청 수 제한이 제대로 되지 않는 문제가 발생합니다. 이를 해결하기 위해 중앙 집중식 저장소(예: Redis, Memcached)를 이용하여 카운터를 공유하거나, 토큰 버킷 등의 알고리즘을 분산 환경에 맞게 재설계해야 합니다. 특히 Redis의 Lua 스크립트를 활용하면 원자성 보장과 성능을 동시에 잡을 수 있으며, Consistent Hashing 같은 기법을 이용해 샤딩도 고려해야 합니다.

### Rate Limiting 알고리즘 중 Token Bucket과 Leaky Bucket의 차이점은 무엇이며, 각각 어떤 상황에 적합한가요?
- Token Bucket은 일정 속도로 토큰을 생성해 버킷에 담고, 요청이 들어오면 토큰을 소비하는 방식으로 동작합니다. 이 방식은 순간적인 트래픽 버스트를 허용하면서도 평균 속도를 제어할 수 있어 유연성이 높습니다. 반면, Leaky Bucket은 일정 속도로만 요청을 처리하도록 제한하며, 들어오는 요청은 큐에 저장됩니다. 이 방식은 요청 속도를 일정하게 유지하고 싶은 경우에 적합합니다. 따라서, Token Bucket은 유저 경험을 해치지 않으면서도 과도한 사용을 제한하고 싶을 때 적합하고, Leaky Bucket은 백엔드 처리 시스템이 일정 처리량 이상을 견디지 못할 때 사용하기 좋습니다.



----

참고링크 
https://yarisong.tistory.com/101#6.%20%EC%9D%B4%EB%8F%99%20%EC%9C%88%EB%8F%84(Sliding%20Window)%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-1

https://duyankim.github.io/cs/2024/09/01/CS29/

